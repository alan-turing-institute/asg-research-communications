# Monitoring the environment

Space-based radars or satellites, unmanned aerial vehicles (drones) and ground-based sensors capture data and measure changes in our environment at various levels. Data from both remote sensing and _in situ_, measurement techniques are combined to observe different ecological systems, such as oceans, forests or volcanoes, and can monitor their conditions over time. AI applications using data from monitoring systems are helping us characterise environmental quality, establish parameters to identify when the quality is compromised and understand the impact those changes have on an environment. AI monitoring technologies are proving to be exceptionally important in translating data into timely responses and improving measures for protected areas and species vulnerable to natural hazards.

AI tools and data-driven models for analysing satellite data allow us to look at the patterns caused by climate change providing a granular level of detail of the Earth’s surface. Ground-based measurements have been critical to understanding specific changes in the atmosphere as well as their impact on local populations ([Gallant et al, 2018](https://www.mdpi.com/1424-8220/18/3/880)). However, their limited scope and area of inference make it challenging to reliably validate those observations in isolation. To make new leaps in understanding environmental change and to improve predictions based on environmental monitoring systems, we need intelligent ways to combine satellite data with surface sensors and the output from physics-based climate models. Computer vision approaches provide an AI-based solution for intelligently making sense of visual data such as satellite images. In combination with algorithms to infer outcomes, computer vision demonstrates huge potential for applications for retrieving and interpreting visual information from environmental data.

## AI method in focus: Computer Vision

Scientific images, videos and other visual information are routinely generated from microscopy, scanning devices, sensors and satellite technologies capturing measurements of changes in different natural systems – ranging from seeds to geospatial landscapes. Manually analysing, classifying and combining information from such large collections of visual data on a varying scale is not only impractical and error-prone but also highly inefficient. Researchers across all areas of interest increasingly rely on AI/ML technology to sift through big data efficiently and reliably. AI technology has also made it possible to automate the detection, classification, tracking and measurement of objects or regions of interest in images using computer vision techniques. Computer vision, like human vision, learns from previous observations or training data to make predictions and decisions in future observations. To avoid errors and biases, computer vision tools are trained on large amounts of visual data to process images at a pixel level and characterise them correctly through pattern recognition.

The remarkable evolution of AI/ML methods and computing power, alongside the generation of large amounts of public image data, has led to the recent developments in computer vision technology. Nonetheless, the majority of datasets used for training computer vision models and algorithms come from transportation, autonomous or computer-assisted automobiles, healthcare, agriculture, retail and construction industries. Largely driven by uneven incentive structures for advancing computer vision in industrial settings, applications of computer vision in scientific and exploratory research have remained underutilised. Another challenge of adopting computer vision in scientific settings is that established models are often trained on RGB (red, green, and blue) data, whereas most image sensors use scientific monochrome image data generated from microscopy images, medical scans, thermal imagery, hyperspectral imagery and radar. There are also challenges associated with reusing existing computer vision tools, models and algorithms trained on natural images that are typically oriented according to our viewpoint and not on objects in all orientations. For instance, pedestrian or traffic flows tend to have a fixed orientation; images of ice flows, forests or landscapes as seen by satellite are not captured from a consistent viewpoint. Trained to recognise patterns from multidimensional visual data, computer vision technology can significantly improve the possibilities to monitor and observe changes in environmental behaviour by identifying factors influencing climate change.

We recommend [General References on Computer Vision](https://www.cs.hmc.edu/~fleck/computer-vision-handbook/general-vision.html) from The Computer Vision Handbook, maintained by, and copyright by, Margaret Fleck of the Computer Science Department at Harvey Mudd College for gaining technical details on Computer Vision. 
